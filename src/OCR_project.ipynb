{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten letter recognition with machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and preparing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing needed libraries (tensorflow and matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used in project is download from http://ai.stanford.edu/~btaskar/ocr/ and converted to csv file type. Dataset contains handwritten words, which have been divided into letters, collected by Rob Kassel at MIT Spoken Language Systems Group.\n",
    "\n",
    "Data contains fields:\n",
    "\n",
    "1. id: each letter is assigned a unique integer id\n",
    "2. letter: a-z\n",
    "3. next_id: id for next letter in the word, -1 if last letter\n",
    "4. word_id: each word is assigned a unique integer id (not used)\n",
    "5. position: position of letter in the word (not used)\n",
    "6. fold: 0-9 -- cross-validation fold\n",
    "7. p_i_j: 0/1 -- value of pixel in row i, column j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convert data to numpy arrays and create dataframe by using pnadas library. The type of integers in array is converted to uint8. 1 is changed to 0 and 0 is changed 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('letter_data.csv','r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    arrays = []\n",
    "    letters = []\n",
    "    for line in csv_reader:\n",
    "        if line[0].isnumeric():\n",
    "            letters.append(line[1])\n",
    "            letter_data = []\n",
    "            first = 6\n",
    "            last = 14\n",
    "            for i in range(16):\n",
    "                row = []\n",
    "                help_list = line[first:last]\n",
    "                \n",
    "                for number in help_list:\n",
    "                    if number == '1':\n",
    "                        row.append(0)\n",
    "                    elif number == '0':\n",
    "                        row.append(255)\n",
    "                \n",
    "                letter_data.append(row)\n",
    "                first += 8; last += 8\n",
    "            letter_array = np.array(letter_data)\n",
    "            arrays.append(letter_array.astype(np.float32))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "data ={'letter': letters, 'array': arrays}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter: m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Letter:\", df.letter[1000])\n",
    "im = df.array[1000]\n",
    "for row in im:\n",
    "    row.astype(np.uint8)\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.letter\n",
    "features = tf.covert_to_tensor(df.array, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0m\u001b[1;32m    466\u001b[0m                   (element, type(element).__name__))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for 0        [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n1        [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n2        [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n3        [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n4        [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n                               ...                        \n52147    [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n52148    [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n52149    [[255.0, 255.0, 0.0, 0.0, 255.0, 255.0, 255.0,...\n52150    [[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 25...\n52151    [[255.0, 0.0, 0.0, 255.0, 255.0, 255.0, 255.0,...\nName: array, Length: 52152, dtype: object with type Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d4cc6ab942a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mletter_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[1;32m    389\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     ))\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    602\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m--> 604\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         normalized_components.append(\n\u001b[0;32m---> 98\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                          as_ref=False):\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "letter_model.fit(features, labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
