{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten letter recognition with machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and preparing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing needed libraries (tensorflow and matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used in project is download from http://ai.stanford.edu/~btaskar/ocr/ and converted to csv file type. Dataset contains handwritten words, which have been divided into letters, collected by Rob Kassel at MIT Spoken Language Systems Group.\n",
    "\n",
    "Data contains fields:\n",
    "\n",
    "1. id: each letter is assigned a unique integer id\n",
    "2. letter: a-z\n",
    "3. next_id: id for next letter in the word, -1 if last letter\n",
    "4. word_id: each word is assigned a unique integer id (not used)\n",
    "5. position: position of letter in the word (not used)\n",
    "6. fold: 0-9 -- cross-validation fold\n",
    "7. p_i_j: 0/1 -- value of pixel in row i, column j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is converted two numpy arrays. Array named letters have info  of letter as ascii value. Types of valeus are floats. Arrays contains the image arrays of letters. Types of values are float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"letter_data.csv\",'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "    arrays = []\n",
    "    letters = []\n",
    "    for line in csv_reader:\n",
    "        if line[0].isnumeric():\n",
    "            letters.append(float(ord(line[1]))) #changed characters to ascii ints and then to floats\n",
    "            letter_data = []\n",
    "            first = 6\n",
    "            last = 14\n",
    "            for i in range(16):\n",
    "                row = line[first:last]\n",
    "                letter_data.append(row)\n",
    "                first += 8; last += 8\n",
    "            letter_array = np.array(letter_data)\n",
    "            arrays.append(letter_array.astype(np.float32))\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are restoreed to variables features and labels. Labels contains Ascii info of letters and features contains image arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(arrays)\n",
    "labels = np.array(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Letter:\", chr(int(labels[2500])))\n",
    "\n",
    "im = features[2500]\n",
    "for row in im:\n",
    "    row.astype(np.uint8)\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(16, 8)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(127)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features, labels, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
